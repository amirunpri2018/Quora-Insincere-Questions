{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Quora Insincere Questions: Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import f1_score, fbeta_score, make_scorer\n",
    "from sklearn import metrics\n",
    "from pylab import rcParams\n",
    "import sys\n",
    "import warnings\n",
    "if not sys.warnoptions:\n",
    "    warnings.simplefilter(\"ignore\")\n",
    "import os\n",
    "os.chdir('/home/roman/Documents/Projects/Quora/data')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --------------- Embedding / Vectorizer --------------- #\n",
    "embedding = 'w2v'   # <-- Specify 'cv', 'tfidf' or 'w2v'\n",
    "embedding_dict = {'cv': 'CountVectorizer', 'tfidf': 'TFIDF Vectorizer', 'w2v': 'Word2Vec'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --------------- Prepare data --------------- #\n",
    "y_train = np.load('y_train.npy')\n",
    "y_val = np.load('y_val.npy')\n",
    "# Count Vectorizer:\n",
    "if embedding == 'cv':\n",
    "    data = pd.read_csv('train.csv')\n",
    "    X_train, X_val, _, _ = train_test_split(data['question_text'], data['target'], \\\n",
    "        test_size=0.1, random_state=123)\n",
    "    count_vectorizer = CountVectorizer(stop_words='english')\n",
    "    count_vectorizer.fit(data['question_text'])\n",
    "    X_train = count_vectorizer.transform(X_train)\n",
    "    X_val = count_vectorizer.transform(X_val)\n",
    "# TFIDF Vectorizer:\n",
    "if embedding == 'tfidf':\n",
    "    data = pd.read_csv('train.csv')\n",
    "    X_train, X_val, _, _ = train_test_split(data['question_text'], data['target'], \\\n",
    "        test_size=0.1, random_state=123)\n",
    "    tfidf_vectorizer = TfidfVectorizer(min_df=3, strip_accents='unicode', token_pattern=r'\\w{1,}', \\\n",
    "                        ngram_range=(1, 3), sublinear_tf=1, stop_words='english')\n",
    "    tfidf_vectorizer.fit(data['question_text'])\n",
    "    X_train = tfidf_vectorizer.transform(X_train)\n",
    "    X_val = tfidf_vectorizer.transform(X_val)\n",
    "# Word2Vec:\n",
    "if embedding == 'w2v':\n",
    "    X_train = np.load('X_train_w2v_w5_s150.npy')\n",
    "    X_val = np.load('X_val_w2v_w5_s150.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --------------- Find parameters with grid search --------------- #\n",
    "f1_scorer = make_scorer(f1_score)\n",
    "param_grid = [{'C': 1, 'class_weight': [{0:.09, 1:.91}, {0:.08, 1:.92}, \\\n",
    "                {0:.07, 1:.93}, {0:.06, 1:.94}, {0:.05, 1:.95}]}]\n",
    "clf = GridSearchCV(LogisticRegression(), param_grid, scoring=f1_scorer) \n",
    "model = clf.fit(X_train, y_train)\n",
    "labels = model.cv_results_['params']\n",
    "tr_score = model.cv_results_['mean_train_score']\n",
    "t_score = model.cv_results_['mean_test_score']\n",
    "rcParams['figure.figsize'] = 8, 4\n",
    "plt.bar(x=np.arange(len(tr_score)) - 0.2,width=0.4, height=tr_score, color='lightblue', label='train score')\n",
    "plt.bar(x=np.arange(len(t_score)) + 0.2,width=0.4, height=t_score, color='blue', label='test score')\n",
    "plt.title('Find best parameters with F beta score (beta=2)')\n",
    "plt.xticks(np.arange(len(labels)), labels, rotation=90)\n",
    "plt.ylabel('F-1 score')\n",
    "plt.legend()\n",
    "plt.grid()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --------------- Logistic Regression --------------- #\n",
    "model = LogisticRegression(C=1, class_weight={0:.07, 1:.93})\n",
    "model.fit(X_train, y_train)\n",
    "y_train_pred = model.predict(X_train)\n",
    "y_val_pred = model.predict(X_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation Logistic Regression with Word2Vec:\n",
      "actual positive:    0.062\n",
      "predicted positive: 0.207\n",
      "precision (train/val/random): 0.247 / 0.244 / 0.062\n",
      "recall (train/val/random):    0.827 / 0.832 / 0.206\n",
      "f1 score (train/val/random):  0.38 / 0.377 / 0.095\n"
     ]
    }
   ],
   "source": [
    "# --------------- Evaluate Results --------------- #\n",
    "predicted_positive = np.round(np.mean(y_train_pred), 3)\n",
    "y_pred_random = np.random.binomial(1, predicted_positive, y_train.shape[0])\n",
    "actual_positve = np.round(np.mean(y_train), 3)\n",
    "precision_train = np.round(metrics.precision_score(y_train, y_train_pred), 3)\n",
    "precision_val = np.round(metrics.precision_score(y_val, y_val_pred), 3)\n",
    "precision_random = np.round(metrics.precision_score(y_train, y_pred_random), 3)\n",
    "recall_train = np.round(metrics.recall_score(y_train, y_train_pred), 3)\n",
    "recall_val = np.round(metrics.recall_score(y_val, y_val_pred), 3)\n",
    "recall_random = np.round(metrics.recall_score(y_train, y_pred_random), 3)\n",
    "f1score_train = np.round(metrics.f1_score(y_train, y_train_pred), 3)\n",
    "f1score_val = np.round(metrics.f1_score(y_val, y_val_pred), 3)\n",
    "f1score_random = np.round(metrics.f1_score(y_train, y_pred_random), 3)\n",
    "print('Evaluation Logistic Regression with {0}:'.format(embedding_dict[embedding]))\n",
    "print('actual positive:    ' + str(np.round(np.mean(y_train), 3)))\n",
    "print('predicted positive: ' + str(np.round(np.mean(y_train_pred), 3)))\n",
    "print('precision (train/val/random): ' + str(precision_train) + ' / ' + \\\n",
    "      str(precision_val) + ' / ' + str(precision_random))\n",
    "print('recall (train/val/random):    ' + str(recall_train) + ' / ' + \\\n",
    "      str(recall_val) + ' / ' + str(recall_random))\n",
    "print('f1 score (train/val/random):  ' + str(f1score_train) + ' / ' + \\\n",
    "      str(f1score_val) + ' / ' + str(f1score_random))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
