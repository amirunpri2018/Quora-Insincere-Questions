{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Quora Insincere Questions: Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn import metrics\n",
    "import sys\n",
    "import warnings\n",
    "if not sys.warnoptions:\n",
    "    warnings.simplefilter(\"ignore\")\n",
    "import os\n",
    "os.chdir('/home/roman/Documents/Projects/Quora/data')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load and prepare data:\n",
    "data = pd.read_csv('train.csv')\n",
    "X_train, X_val, y_train, y_val = train_test_split(data['question_text'], data['target'], test_size=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --------------- CountVectorizer --------------- #\n",
    "count_vectorizer = CountVectorizer(stop_words='english')\n",
    "count_vectorizer.fit(data['question_text'])\n",
    "X_train_count_vec = count_vectorizer.transform(X_train)\n",
    "X_val_count_vec = count_vectorizer.transform(X_val)\n",
    "model = LogisticRegression()\n",
    "model.fit(X_train_count_vec, y_train)\n",
    "y_train_count_pred = model.predict(X_train_count_vec)\n",
    "y_val_count_pred = model.predict(X_val_count_vec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --------------- TFIDF Vectorizer --------------- #\n",
    "tfidf_vectorizer = TfidfVectorizer(min_df=3, strip_accents='unicode', token_pattern=r'\\w{1,}', \\\n",
    "                        ngram_range=(1, 3), sublinear_tf=1, stop_words='english')\n",
    "tfidf_vectorizer.fit(data['question_text'])\n",
    "X_train_tfidf_vec = tfidf_vectorizer.transform(X_train)\n",
    "X_val_tfidf_vec = tfidf_vectorizer.transform(X_val)\n",
    "model = LogisticRegression()\n",
    "model.fit(X_train_tfidf_vec, y_train)\n",
    "y_train_tfidf_pred = model.predict(X_train_tfidf_vec)\n",
    "y_val_tfidf_pred = model.predict(X_val_tfidf_vec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation Logistic Regression with CountVectorizer:\n",
      "actual positive:    0.062\n",
      "predicted positive: 0.039\n",
      "precision (train/val/random): 0.753 / 0.684 / 0.06\n",
      "recall (train/val/random):    0.472 / 0.414 / 0.038\n",
      "f1 score (train/val/random):  0.58 / 0.516 / 0.046\n",
      "\n",
      "\n",
      "Evaluation Logistic Regression with TFIDFVectorizer:\n",
      "actual positive:    0.062\n",
      "predicted positive: 0.034\n",
      "precision (train/val/random): 0.774 / 0.693 / 0.061\n",
      "recall (train/val/random):    0.426 / 0.363 / 0.034\n",
      "f1 score (train/val/random):  0.55 / 0.477 / 0.043\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# --------------- Evaluate Results --------------- #\n",
    "predicted_positive = np.round(np.mean(y_train_count_pred), 3)\n",
    "y_pred_random = np.random.binomial(1, predicted_positive, y_train.shape[0])\n",
    "actual_positve = np.round(np.mean(y_train), 3)\n",
    "precision_train = np.round(metrics.precision_score(y_train, y_train_count_pred), 3)\n",
    "precision_val = np.round(metrics.precision_score(y_val, y_val_count_pred), 3)\n",
    "precision_random = np.round(metrics.precision_score(y_train, y_pred_random), 3)\n",
    "recall_train = np.round(metrics.recall_score(y_train, y_train_count_pred), 3)\n",
    "recall_val = np.round(metrics.recall_score(y_val, y_val_count_pred), 3)\n",
    "recall_random = np.round(metrics.recall_score(y_train, y_pred_random), 3)\n",
    "f1score_train = np.round(metrics.f1_score(y_train, y_train_count_pred), 3)\n",
    "f1score_val = np.round(metrics.f1_score(y_val, y_val_count_pred), 3)\n",
    "f1score_random = np.round(metrics.f1_score(y_train, y_pred_random), 3)\n",
    "print('Evaluation Logistic Regression with CountVectorizer:')\n",
    "print('actual positive:    ' + str(np.round(np.mean(y_train), 3)))\n",
    "print('predicted positive: ' + str(np.round(np.mean(y_train_count_pred), 3)))\n",
    "print('precision (train/val/random): ' + str(precision_train) + ' / ' + \\\n",
    "      str(precision_val) + ' / ' + str(precision_random))\n",
    "print('recall (train/val/random):    ' + str(recall_train) + ' / ' + \\\n",
    "      str(recall_val) + ' / ' + str(recall_random))\n",
    "print('f1 score (train/val/random):  ' + str(f1score_train) + ' / ' + \\\n",
    "      str(f1score_val) + ' / ' + str(f1score_random))\n",
    "print('\\n')\n",
    "predicted_positive = np.round(np.mean(y_train_tfidf_pred), 3)\n",
    "y_pred_random = np.random.binomial(1, predicted_positive, y_train.shape[0])\n",
    "precision_train = np.round(metrics.precision_score(y_train, y_train_tfidf_pred), 3)\n",
    "precision_val = np.round(metrics.precision_score(y_val, y_val_tfidf_pred), 3)\n",
    "precision_random = np.round(metrics.precision_score(y_train, y_pred_random), 3)\n",
    "recall_train = np.round(metrics.recall_score(y_train, y_train_tfidf_pred), 3)\n",
    "recall_val = np.round(metrics.recall_score(y_val, y_val_tfidf_pred), 3)\n",
    "recall_random = np.round(metrics.recall_score(y_train, y_pred_random), 3)\n",
    "f1score_train = np.round(metrics.f1_score(y_train, y_train_tfidf_pred), 3)\n",
    "f1score_val = np.round(metrics.f1_score(y_val, y_val_tfidf_pred), 3)\n",
    "f1score_random = np.round(metrics.f1_score(y_train, y_pred_random), 3)\n",
    "print('Evaluation Logistic Regression with TFIDFVectorizer:')\n",
    "print('actual positive:    ' + str(np.round(np.mean(y_train), 3)))\n",
    "print('predicted positive: ' + str(np.round(np.mean(y_train_tfidf_pred), 3)))\n",
    "print('precision (train/val/random): ' + str(precision_train) + ' / ' + \\\n",
    "      str(precision_val) + ' / ' + str(precision_random))\n",
    "print('recall (train/val/random):    ' + str(recall_train) + ' / ' + \\\n",
    "      str(recall_val) + ' / ' + str(recall_random))\n",
    "print('f1 score (train/val/random):  ' + str(f1score_train) + ' / ' + \\\n",
    "      str(f1score_val) + ' / ' + str(f1score_random))\n",
    "print('\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With a logistic regression model the simpler and faster CountVectorizer performs slightly better than a TFIDF Vectorizer"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
